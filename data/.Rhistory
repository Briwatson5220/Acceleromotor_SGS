}
names(dat)<-c("id", "nobs")
complete2("specdata", 1)
length(good[good])
complete2 <- function(directory, id = 1:332) {
tmp <- vector(mode = "list", length = length(files_full))
for(i in id) {
fileName <- paste(directory, "/", sprintf("%03d.csv", i), sep = "")
tmp[[i]] <- read.csv(fileName) # read each table into the new element in list
}
dat <- data.frame()
for(i in id) {
good <- complete.cases(tmp[[i]])
dat[i, 1] <- i
dat[i, 2] <- length(good[good])
}
names(dat)<-c("id", "nobs")
dat
}
complete2("specdata", 1)
complete("specdata", c(2, 4, 8, 10, 12))
complete2("specdata", c(2, 4, 8, 10, 12))
complete2 <- function(directory, id = 1:332) {
tmp <- vector(mode = "list", length = length(files_full))
for(i in id) {
fileName <- paste(directory, "/", sprintf("%03d.csv", i), sep = "")
tmp[[i]] <- read.csv(fileName) # read each table into the new element in list
}
dat <- data.frame()
rowCount = 0
for(i in id) {
rowCount <- rowCount + 1
good <- complete.cases(tmp[[i]])
dat[rowCount, 1] <- i
dat[rowCount, 2] <- length(good[good])
}
names(dat)<-c("id", "nobs")
dat
}
complete2("specdata", c(2, 4, 8, 10, 12))
tmp <- vector(mode = "list", length = length(files_full))
for(i in id) {
fileName <- paste(directory, "/", sprintf("%03d.csv", i), sep = "")
tmp[[i]] <- read.csv(fileName) # read each table into the new element in list
}
dat <- data.frame()
rowCount = 0
list_id <-vector()
list_nob <-vector()
for(i in id) {
rowCount <- rowCount + 1
good <- complete.cases(tmp[[i]])
dat[rowCount, 1] <- i
dat[rowCount, 2] <- length(good[good])
list_id[rowCount] <-i
list_nob[rowCount] <- length(good[good])
}
names(dat)<-c("id", "nobs")
dat2 <- cbind(list_id, list_nob
dat2
dat2 <- cbind(list_id, list_nob)
dat2
names(dat2)
summary(dat2)
names(dat2)<-c("id", "nobs")
summary(dat2)
makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
cachemean <- function(x, ...) {
m <- x$getmean()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- mean(data, ...)
x$setmean(m)
m
}
vector <- c(1, 2, 3)
cachemean <- vector
makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
cachemean <- function(x, ...) {
m <- x$getmean()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- mean(data, ...)
x$setmean(m)
m
}
temp <- cachemean(vector)
temp <- makevector(vector)
temp <- makeVector(vector)
temp
temp <- cachemean(vector)
tempVector <- numeric(1, 2, 3)
tempVector <- c(1, 2, 3)
summary(tempVector)
tempVector
about(tempVector)
names(tempVector) <- c("x", "y", "z")
temp <- cachemean(tempVector)
a <- makeVector(c(1,2,3,4))
a$get()
a$setmean()
a$getmean()
cachmean(a)
cachemean(a)
a$getmean()
cachemean(a)
amatrix <-matrix(c(1,2,3,4), nrow=2, ncol=2)
tempMatrix <-solve(amatrix)
tempMatrix
amatrix = makeCacheMatrix(matrix(c(1,2,3,4), nrow=2, ncol=2))
amatrix = matrix(c(1,2,3,4), nrow=2, ncol=2)
solve(amatrix)
makeCacheMatrix <- function(x = matrix()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setinverse <- function(inverse) m <<- inverse
getinverse <- function() m
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
## Write a short comment describing this function
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
m <- x$getinverse()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- solve(data, ...)
x$setinverse(m)
m
}
amatrix = makeCacheMatrix(matrix(c(1,2,3,4), nrow=2, ncol=2))
amatrix$get()
cacheSolve(amatrix)
amatrix$getinverse()
cacheSolve(amatrix)
amatrix$set(matrix(c(0,5,99,66), nrow=2, ncol=2))
cacheSolve(amatrix)
amatrix$get()
amatrix$getinverse()
cacheSolve(amatrix)
library(datasets)
data(iris)
iris
tempArray<-iris[1:2, 1]
mean(tempArray)
tempArray<-iris[, 1]
tempArray<-tapply(iris, iris[, 5], mean)
tempArray<-tapply(iris[, 1], iris[, 5], mean)
tempArray
apply(iris, 2, mean)
apply(iris[, 1:4], 2, mean)
library(datasets)
data(mtcars)
?mtcars
tapply(mtcars$cyl, mtcars$mpg, mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
sapply(split(mtcars$hp, mtcars$cyl), mean)
209.21429 - 82.63636
sapply(split(mtcars$hp, mtcars$cyl=8), mean)
sapply(split(mtcars$hp, mtcars$cyl==8), mean)
sapply(split(mtcars$hp, mtcars$cyl==8), mean)=true - sapply(split(mtcars$hp, mtcars$cyl==4), mean)=true
sapply(split(mtcars$hp, mtcars$cyl==8), mean)=TRUE - sapply(split(mtcars$hp, mtcars$cyl==4), mean)=TRUE
sapply(split(mtcars$hp, mtcars$cyl==8), mean)==TRUE - sapply(split(mtcars$hp, mtcars$cyl==4), mean)==TRUE
debug(cachemean)
cachemean(1:3)
set.seed(1)
rpois(5, 2)
library(XML)
install.packages(XML)
install.packages("XML")
library(XML)
doc <- xmlTreeParse("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml")
doc <- xmlTreeParse("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml", useInternal=TRUE)
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileURL, useInternal=TRUE)
doc <- htmlTreeParse(fileURL, useInternal=TRUE)
fileURL <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileURL, useInternal=TRUE)
rootNode <- xmlRoot(doc)
names(rootNode)
rootNode[[1]]
xpathSApply(rootNode, "//zipcode", xmlValue)
lenght(xpathSApply(rootNode, "//zipcode", xmlValue)="21224")
length(xpathSApply(rootNode, "//zipcode", xmlValue)="21224")
length(xpathSApply(rootNode, "//zipcode", xmlValue)=="21224")
length(xpathSApply(rootNode, "//zipcode", xmlValue)=="21231")
xpathSApply(rootNode, "//zipcode", xmlValue)=="21231"
tempZip <- xpathSApply(rootNode, "//zipcode", xmlValue)
tempZip
tempZip["21231"]
tempZip[xpathSApply(rootNode, "//zipcode", xmlValue)=="21231"]
length(tempZip[xpathSApply(rootNode, "//zipcode", xmlValue)=="21231"])
read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
Housing <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
?fread
?fread()\
?fread()
??fread
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileURL, destFile = "Housing.csv")
download.file(fileURL, destfile = "Housing.csv")
getwd()
dt<-fread("Housing.csv")
install.packages("fread")
library(data.table)
install("data.table"
)
install.packages("data.table")
library(data.table)
?fread
fread("Housing.csv")
DT <- fread("Housing.csv")
sapply(split(DT$pwgtp15,DT$SEX),mean)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
tapply(DT$pwgtp15,DT$SEX,mean)
DT[,mean(pwgtp15),by=SEX]
system.tim(DT[,mean(pwgtp15),by=SEX])
system.time(DT[,mean(pwgtp15),by=SEX])
DT[,mean(pwgtp15),by=SEX]
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
?system.time
system.time(for(i in 1:100) mad(runif(1000)))
system.time(for(i in 1:100) mad(runif(1000)))*1000
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))*100
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))*1000
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))*100000
proc.time()
proc.time()
proc.time()
ptm <- proc.time()
for (i in 1:50) mad(stats::runif(500))
proc.time() - ptm
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
sapply(split(DT$pwgtp15,DT$SEX),mean)
ptm <- proc.time()
sapply(split(DT$pwgtp15,DT$SEX),mean)
proc.time() - ptm
ptm <- proc.time()
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
proc.time() - ptm
ptm <- proc.time()
tapply(DT$pwgtp15,DT$SEX,mean)
proc.time() - ptm
ptm <- proc.time()
DT[,mean(pwgtp15),by=SEX]
proc.time() - ptm
ptm <- proc.time()
mean(DT$pwgtp15,by=DT$SEX)
proc.time() - ptm
mean(DT$pwgtp15,by=DT$SEX)
ptm <- proc.time()
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
proc.time() - ptm
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
ls()
rm(list=ls())
swirl()
mydf<-read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVerstion("dplyr")
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
?tbl_df
cram
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(x:size))
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1",country == "US")
?Comparison
filter(cran, r_version <= "3.0.2",country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os = "linux-gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3<-select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_gb = size_mb / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size=size+1000)
summarize(cran, avg_bytes = mean(size))
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("c35f99f914432578d037", "77cc4286533787007ac33e9402519a87dc7eab5f")
?oauth_app
myapp <- oauth_app("github", "c35f99f914432578d037", "77cc4286533787007ac33e9402519a87dc7eab5f")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
myapp <- oauth_app("github", "c35f99f914432578d037", "77cc4286533787007ac33e9402519a87dc7eab5f")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
?httpuv
install(httpuv)
?install
??install
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "56b637a5baffac62cad9")
myapp <- oauth_app("github", "c35f99f914432578d037", "77cc4286533787007ac33e9402519a87dc7eab5f")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
install.packages(httpuv)
install.packages("httpuv")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
head(req)
summary(rep)
summary(req)
??created
content(req)
path2csv<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
acs<-read.csv(path2csv, stringsAsFactors = FALSE)
sqldf("select distinct AGEP from acs")
install.packages("sqldf")
sqldf("select distinct AGEP from acs")
load("sqldf")
library("sqldf")
sqldf("select distinct AGEP from acs")
con=url("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
htmlCode = readlines(con)
htmlCode = readLines(con)
close(con)
htmlCode
?nchar
htmlCode[10]
htmlCode[10000]
nchar(htmlCode[10])
con=url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readLines(con)
close(con)
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
path2csv<-"https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
mydf<-read.csv(path2csv, stringsAsFactors = FALSE)
mydf
?read.csv
head(mydf)
?read.fwf
path2csv<-"https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
myfwf<-read.fwf(path2csv,  skip=4, widths=c(12, 7,4, 9,4, 9,4, 9,4))
head(myfwf)
sum(myfwf[, 4], myfwf[, 9])
sum(myfwf[, 4])
sum(myfwf[, 9])
library(reshape2)
library(dplyr)
# Download data
###setwd("E:/Users/Brian/Documents/My Data/Acceleromotor/Acceleromotor_SGS/data")
# if(!file.exists("./data")){dir.create("./data")}
# url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
# download.file(url, "./data/dataset.zip", mode="wb", method="curl")
# unzip("./data/dataset.zip", exdir = "./data")
# unlink(url)
# Merge the training and the test sets to create one data set.
# Measurements
Measurement_train <- read.table("./UCI HAR Dataset/train/X_train.txt", header=F,sep="")
Measurement_test <- read.table("./UCI HAR Dataset/test/X_test.txt", header=F,sep="")
Measurement <- rbind(Measurement_train, Measurement_test)
# Activity information
Type_train <- read.table("./UCI HAR Dataset/train/Y_train.txt", header=F,sep="")
Type_test <- read.table("./UCI HAR Dataset/test/Y_test.txt", header=F,sep="")
Type <- rbind(Type_train, Type_test)
# Load actual Activity names
Activity_Labels <- read.table("./UCI HAR Dataset/activity_labels.txt", header=F,sep="")
Type <- merge(Type, Activity_Labels)
colnames(Type) <- c("ActivityID", "Activity")
# Subjects
Subject_train <- read.table("./UCI HAR Dataset/train/subject_train.txt", header=F,sep="")
Subject_test <- read.table("./UCI HAR Dataset/test/subject_test.txt", header=F,sep="")
Subject <- rbind(Subject_train, Subject_test)
colnames(Subject) <- "SubjectID"
# Extract only the measurements on the mean and standard deviation for each measurement.
Features <- read.table("./UCI HAR Dataset/features.txt", header=F,sep="")
Columns_std <- grep("[.]std[.]", make.names(Features[, 2]))
Columns_mean <- grep("[.]mean[.]", make.names(Features[, 2]))
Features_Columns <- c(Columns_mean, Columns_std) #list of all columns to include
DataTemp <- Measurement[, Features_Columns] #just the std and mean
colnames(DataTemp) <- make.names(Features[Features_Columns, 2]) #correct the column names
DataTemp <- cbind(Subject, Type, DataTemp)
# cleanup the data into 1 table with just the SujectID, Activity, Variable and Value columns
Data <- melt(DataTemp, id=c("SubjectID", "Activity"), measure.vars=make.names(Features[Features_Columns, 2]))
dat <- data.frame() # this is just an empty data frame for the rbind to add it to
for (i in 1:length(Features[Columns_std, 2])){
dat[i, 1] <- make.names(Features[Columns_std, 2][i])
tempDat <- unlist(strsplit(make.names(Features[Features_Columns, 2][i]), "\\."))
dat[i, 2] <- tempDat[1]
dat[i, 3] <- tempDat[2]
dat[i, 4] <- tempDat[length(tempDat)]
}
setwd("E:/Users/Brian/Documents/My Data/Acceleromotor/Acceleromotor_SGS/data")
Measurement_train <- read.table("./UCI HAR Dataset/train/X_train.txt", header=F,sep="")
Measurement_test <- read.table("./UCI HAR Dataset/test/X_test.txt", header=F,sep="")
Measurement <- rbind(Measurement_train, Measurement_test)
# Activity information
Type_train <- read.table("./UCI HAR Dataset/train/Y_train.txt", header=F,sep="")
Type_test <- read.table("./UCI HAR Dataset/test/Y_test.txt", header=F,sep="")
Type <- rbind(Type_train, Type_test)
# Load actual Activity names
Activity_Labels <- read.table("./UCI HAR Dataset/activity_labels.txt", header=F,sep="")
Type <- merge(Type, Activity_Labels)
colnames(Type) <- c("ActivityID", "Activity")
# Subjects
Subject_train <- read.table("./UCI HAR Dataset/train/subject_train.txt", header=F,sep="")
Subject_test <- read.table("./UCI HAR Dataset/test/subject_test.txt", header=F,sep="")
Subject <- rbind(Subject_train, Subject_test)
colnames(Subject) <- "SubjectID"
# Extract only the measurements on the mean and standard deviation for each measurement.
Features <- read.table("./UCI HAR Dataset/features.txt", header=F,sep="")
Columns_std <- grep("[.]std[.]", make.names(Features[, 2]))
Columns_mean <- grep("[.]mean[.]", make.names(Features[, 2]))
Features_Columns <- c(Columns_mean, Columns_std) #list of all columns to include
DataTemp <- Measurement[, Features_Columns] #just the std and mean
colnames(DataTemp) <- make.names(Features[Features_Columns, 2]) #correct the column names
DataTemp <- cbind(Subject, Type, DataTemp)
# cleanup the data into 1 table with just the SujectID, Activity, Variable and Value columns
Data <- melt(DataTemp, id=c("SubjectID", "Activity"), measure.vars=make.names(Features[Features_Columns, 2]))
dat <- data.frame() # this is just an empty data frame for the rbind to add it to
for (i in 1:length(Features[Columns_std, 2])){
dat[i, 1] <- make.names(Features[Columns_std, 2][i])
tempDat <- unlist(strsplit(make.names(Features[Features_Columns, 2][i]), "\\."))
dat[i, 2] <- tempDat[1]
dat[i, 3] <- tempDat[2]
dat[i, 4] <- tempDat[length(tempDat)]
}
# create a second, independent tidy data set with the average of each variable for each
# activity and each subject.
Data_Tidy <- summarise(group_by(Data, SubjectID, Activity, variable), mean(value))
tempDatDat <- merge(Data, dat, by.x="variable", by.y="v1", all=TRUE)
head(dat)
head(data)
head(Data)
names(dat)<-c("variable", "metric", "measure", "dimension")
head(dat)
tempDatDat <- merge(Data, dat)
head(tempDatDat)
Data_Tidy <- summarise(group_by(Data, SubjectID, Activity, metric, measure, dimension), mean(value))
Data <- merge(Data, dat)
Data_Tidy <- summarise(group_by(Data, SubjectID, Activity, metric, measure, dimension), mean(value))
write.table(Data_Tidy, "Data_Tidy.txt")
write.table(Data_Tidy, "Data_Tidy.txt", row.name=FALSE
)
_by(Data, SubjectID, Activity, variable), mean(value))
Data_Tidy <- summarise(group_by(Data, SubjectID, Activity, variable), mean(value))
write.table(Data_Tidy, "Data_Tidy.txt", row.name=FALSE
)
summary(Data[, 5])
group_by(Data, metric)
summarise(group_by(Data, metric))
summarise(group_by(Data, Activity))
